{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Agents Lab Notebook v1.0.0\nThis notebook contains steps and code to demonstrate the use of agents\nconfigured in Agent Lab in watsonx.ai. It introduces Python API commands\nfor authentication using API key and invoking a LangGraph agent with a watsonx chat model.\n\n**Note:** Notebook code generated using Agent Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n\nSome familiarity with Python is helpful. This notebook uses Python 3.11.\n\n## Notebook goals\nThe learning goals of this notebook are:\n\n* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n* Creating an agent with a set of tools using a specified model and parameters\n* Invoking the agent to generate a response \n\n# Setup"}, {"metadata": {}, "cell_type": "code", "source": "# import dependencies\nfrom langchain_ibm import ChatWatsonx\nfrom ibm_watsonx_ai import APIClient\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.prebuilt import create_react_agent\nfrom ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\nimport json\nimport requests", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"}, {"metadata": {}, "cell_type": "code", "source": "import os\nimport getpass\n\ndef get_credentials():\n\treturn {\n\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n\t}\n\ndef get_bearer_token():\n    url = \"https://iam.cloud.ibm.com/identity/token\"\n    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n    data = f\"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={credentials['apikey']}\"\n\n    response = requests.post(url, headers=headers, data=data)\n    return response.json().get(\"access_token\")\n\ncredentials = get_credentials()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Using the agent\nThese cells demonstrate how to create and invoke the agent\nwith the selected models, tools, and parameters.\n\n## Defining the model id\nWe need to specify model id that will be used for inferencing:"}, {"metadata": {}, "cell_type": "code", "source": "model_id = \"ibm/granite-3-3-8b-instruct\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the model parameters\nWe need to provide a set of model parameters that will influence the\nresult:"}, {"metadata": {}, "cell_type": "code", "source": "parameters = {\n    \"frequency_penalty\": 0,\n    \"max_tokens\": 2000,\n    \"presence_penalty\": 0,\n    \"temperature\": 0,\n    \"top_p\": 1\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the project id or space id\nThe API requires project id or space id that provides the context for the call. We will obtain\nthe id from the project or space in which this notebook runs:"}, {"metadata": {}, "cell_type": "code", "source": "project_id = os.getenv(\"PROJECT_ID\")\nspace_id = os.getenv(\"SPACE_ID\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Creating the agent\nWe need to create the agent using the properties we defined so far:"}, {"metadata": {}, "cell_type": "code", "source": "client = APIClient(credentials=credentials, project_id=project_id, space_id=space_id)\n\n# Create the chat model\ndef create_chat_model():\n    chat_model = ChatWatsonx(\n        model_id=model_id,\n        url=credentials[\"url\"],\n        space_id=space_id,\n        project_id=project_id,\n        params=parameters,\n        watsonx_client=client,\n    )\n    return chat_model", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watsonx_ai.deployments import RuntimeContext\n\ncontext = RuntimeContext(api_client=client)\n\n\nvector_index_id = \"ce4ea23d-fbd2-4331-bd36-7f778bcb658e\"\n\ndef create_rag_tool(vector_index_id, api_client):\n    config = {\n        \"vectorIndexId\": vector_index_id,\n        \"projectId\": project_id\n    }\n\n    tool_description = \"Search information in documents to provide context to a user query. Useful when asked to ground the answer in specific knowledge about SBAIA\"\n    \n    return create_utility_agent_tool(\"RAGQuery\", config, api_client, tool_description=tool_description)\n\n\n\ndef create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n    from langchain_core.tools import StructuredTool\n    utility_agent_tool = Toolkit(\n        api_client=api_client\n    ).get_tool(tool_name)\n\n    tool_description = utility_agent_tool.get(\"description\")\n\n    if (kwargs.get(\"tool_description\")):\n        tool_description = kwargs.get(\"tool_description\")\n    elif (utility_agent_tool.get(\"agent_description\")):\n        tool_description = utility_agent_tool.get(\"agent_description\")\n    \n    tool_schema = utility_agent_tool.get(\"input_schema\")\n    if (tool_schema == None):\n        tool_schema = {\n            \"type\": \"object\",\n            \"additionalProperties\": False,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n            \"properties\": {\n                \"input\": {\n                    \"description\": \"input for the tool\",\n                    \"type\": \"string\"\n                }\n            }\n        }\n    \n    def run_tool(**tool_input):\n        query = tool_input\n        if (utility_agent_tool.get(\"input_schema\") == None):\n            query = tool_input.get(\"input\")\n\n        results = utility_agent_tool.run(\n            input=query,\n            config=params\n        )\n        \n        return results.get(\"output\")\n    \n    return StructuredTool(\n        name=tool_name,\n        description = tool_description,\n        func=run_tool,\n        args_schema=tool_schema\n    )\n\n\ndef create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n    from langchain_core.tools import StructuredTool\n    import ast\n\n    def call_tool(**kwargs):\n        tree = ast.parse(tool_code, mode=\"exec\")\n        custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n        function_name = custom_tool_functions[0].name\n        compiled_code = compile(tree, 'custom_tool', 'exec')\n        namespace = tool_params if tool_params else {}\n        exec(compiled_code, namespace)\n        return namespace[function_name](**kwargs)\n        \n    tool = StructuredTool(\n        name=tool_name,\n        description = tool_description,\n        func=call_tool,\n        args_schema=tool_schema\n    )\n    return tool\n\ndef create_custom_tools():\n    custom_tools = []\n\n\ndef create_tools(context):\n    tools = []\n    tools.append(create_rag_tool(vector_index_id, client))\n    \n    config = None\n    tools.append(create_utility_agent_tool(\"GoogleSearch\", config, client))\n    config = {\n    }\n    tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, client))\n    config = {\n        \"maxResults\": 5\n    }\n    tools.append(create_utility_agent_tool(\"Wikipedia\", config, client))\n    config = {\n    }\n    tools.append(create_utility_agent_tool(\"WebCrawler\", config, client))\n\n    return tools", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def create_agent(context):\n    # Initialize the agent\n    chat_model = create_chat_model()\n    tools = create_tools(context)\n\n    memory = MemorySaver()\n    instructions = \"\"\"You are a helpful, intelligent, and detail-oriented AI assistant. Your job is to understand user questions, retrieve or generate accurate answers, and explain them clearly.\n\nAlways:\n- Be polite and professional\n- Respond step-by-step when needed\n- Ask clarifying questions if the input is vague\n- Provide structured answers (use lists, sections, or tables if helpful)\n- Avoid making up facts; rely on reliable data or tools\n- Keep responses concise but informative\n\nWhen greeted, say:  \n\u201cHi, I\u2019m your AI assistant. How can I help you today?\u201d\n\nIf a task involves multiple parts, break it into steps. If you're unable to answer due to missing information, ask the user politely to provide more details.\n\nInstructions for Startup Blueprint Generator Agent**\n\nYou are an intelligent and resourceful AI assistant named **Startup Blueprint Generator Agent**. Your primary function is to transform a user\u2019s raw or loosely described startup idea into a **clear, comprehensive, and actionable startup blueprint**.\n\n---\n\n### \ud83c\udfaf **Your Objective**\n\nUnderstand the user's idea, augment it with real-world context using retrieved data, and deliver a complete startup plan that empowers aspiring entrepreneurs to take confident action.\n\n---\n\n### \ud83d\udccc **Your Responsibilities**\n\nUpon receiving a startup idea from the user (even if described casually), follow this workflow:\n\n1. **Interpret the Idea**\n\n   * Understand the core concept, problem, or industry.\n   * Ask clarifying questions if the input is too vague or lacks context.\n\n2. **Retrieve Relevant Context** (if retrieval is enabled or simulated)\n\n   * Market trends or comparable startup models\n   * Government schemes and startup incentives\n   * Competitor landscape\n   * Regulatory/legal frameworks\n   * Incubator or investor opportunities\n\n3. **Generate a Structured Startup Blueprint**\n   Present the output in a clean, organized format covering the following sections:\n\n---\n\n### \ud83e\udde9 **Startup Blueprint Structure**\n\n\ud83d\udd39 **1. One-Line Summary**\n\n> A concise description of the startup idea.\n\n\ud83d\udd39 **2. Business Model Canvas**\n\n* Key Partners\n* Key Activities\n* Value Proposition\n* Customer Segments\n* Channels\n* Customer Relationships\n* Key Resources\n* Cost Structure\n* Revenue Streams\n\n\ud83d\udd39 **3. Estimated Budget**\n\n> A rough estimate of startup costs in INR or USD (for MVP or initial launch).\n\n\ud83d\udd39 **4. Go-To-Market (GTM) Strategy**\n\n> Suggest launch strategies, distribution channels, and user acquisition tactics.\n\n\ud83d\udd39 **5. Competitor Analysis**\n\n> List at least 2\u20133 similar startups or indirect competitors and their strengths.\n\n\ud83d\udd39 **6. Government Schemes & Funding Options**\n\n> Recommend relevant schemes (e.g., Startup India Seed Fund, MeitY TIDE 2.0, MSME support).\n\n\ud83d\udd39 **7. Legal & Compliance Requirements**\n\n> Mention key registrations and legal obligations (e.g., MSME, DPIIT, GST, IP protection).\n\n\ud83d\udd39 **8. Suggested Investors or Incubators**\n\n> Highlight potential VCs, angel investors, or accelerators aligned with the domain.\n\n---\n\n### \u2728 **Formatting Guidelines**\n\n* Use headings and bullet points for clarity\n* Avoid overly technical language unless requested\n* Keep tone professional, encouraging, and actionable\n* If data is unavailable, make intelligent assumptions or mention that information retrieval is limited\n\n\n\n**One-Line Summary:**\nExample (A smart mirror using AI to recommend outfit combinations based on user wardrobe and personal style.)\n\n**Business Model Canvas:**\n\n* Key Partners: Example (Fashion retailers, AI development teams)\n* Value Proposition: Example (Personalized styling at home)\n* ... *(other components)*\n\n**Estimated Budget:** Example (\u20b98\u201310 Lakhs) (prototype + app development)\n**GTM Strategy:** Example (Launch in Tier-1 cities, partner with fashion influencers)\n**Competitors:** Example (StyleDotMe, Zyler)\n**Govt Schemes:** Example (Startup India Seed Fund, MeitY TIDE 2.0)\n**Legal:** Example (MSME registration, AI data privacy compliance)\n**Investors:** Example (Blume Ventures, 100X.VC)\n\n---\n\n### \ud83d\udfe1 **If Input Is Too Vague:**\n\nAsk politely for more context like:\n\n* Target user group (e.g., students, farmers, professionals)\n* Problem being solved\n* Industry/sector (e.g., health, education, logistics)\n\n---\n\"\"\"\n\n    agent = create_react_agent(chat_model, tools=tools, checkpointer=memory, state_modifier=instructions)\n\n    return agent", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Visualize the graph\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n\nImage(\n    create_agent(context).get_graph().draw_mermaid_png(\n        draw_method=MermaidDrawMethod.API,\n    )\n)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Invoking the agent\nLet us now use the created agent, pair it with the input, and generate the response to your question:\n"}, {"metadata": {}, "cell_type": "code", "source": "agent = create_agent(context)\n\ndef convert_messages(messages):\n    converted_messages = []\n    for message in messages:\n        if (message[\"role\"] == \"user\"):\n            converted_messages.append(HumanMessage(content=message[\"content\"]))\n        elif (message[\"role\"] == \"assistant\"):\n            converted_messages.append(AIMessage(content=message[\"content\"]))\n    return converted_messages\n\nquestion = input(\"Question: \")\n\nmessages = [{\n    \"role\": \"user\",\n    \"content\": question\n}]\n\ngenerated_response = agent.invoke(\n    { \"messages\": convert_messages(messages) },\n    { \"configurable\": { \"thread_id\": \"42\" } }\n)\n\nprint_full_response = False\n\nif (print_full_response):\n    print(generated_response)\nelse:\n    result = generated_response[\"messages\"][-1].content\n    print(f\"Agent: {result}\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Next steps\nYou successfully completed this notebook! You learned how to use\nwatsonx.ai inferencing SDK to generate response from the foundation model\nbased on the provided input, model id and model parameters. Check out the\nofficial watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}}, "nbformat": 4, "nbformat_minor": 0}